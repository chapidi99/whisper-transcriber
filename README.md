Building a Multilingual Transcription App Using Whisper and Streamlit
ğŸš€ Why I Built ThisÂ App
In a recent research project, our team was tasked with transcribing hundreds of hours of interviews conducted in German and Turkish. However, due to policy constraints, we were required to use an officially approved toolâ€Š-â€ŠAmberscriptâ€Š-â€Šfor the final transcription. While Amberscript is a great tool, I realized there are moments in research and academic work where having an in-house, open-source transcription solution could provide:
âœ… Flexibility to handle different languages
âœ… Full control over data (especially for sensitive files)
âœ… Zero cost at scale
âœ… Customizability to add features like translation, summarization, etc.
That curiosity led me to build this lightweight yet powerful web-based transcription app using OpenAI's Whisper model and Streamlit.
ğŸ“„ The Code (whisper_app.py)
import streamlit as st
import whisper
import tempfile

st.title("ğŸ· Multilingual Audio Transcription with Whisper")

# Language selector
target_language = st.selectbox(
    "ğŸŒ Select transcription language:",
    ["de", "tr"],
    format_func=lambda x: "German ğŸ‡©ğŸ‡ª" if x == "de" else "Turkish ğŸ‡¹ğŸ‡·"
)

# File uploader
audio_file = st.file_uploader("Upload audio file", type=["mp3", "wav", "m4a"])

if audio_file is not None:
    st.audio(audio_file)

    with st.spinner("Transcribing... â³"):
        # Save file temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix=audio_file.name) as tmp_file:
            tmp_file.write(audio_file.read())
            tmp_path = tmp_file.name

        # Load Whisper model on CPU
        model = whisper.load_model("medium", device="cpu")

        # Transcribe the audio
        result = model.transcribe(tmp_path, language=target_language)

        # Show transcription
        st.subheader("ğŸ“ Transcription")
        st.write(result["text"])
ğŸ”— Deploying It on Streamlit Cloud
Create a GitHub repository
Add whisper_app.py and this requirements.txt:

streamlit
openai-whisper
torch
ffmpeg-python
3. Go to streamlit.io/cloud
4. Connect your GitHub repo and deploy
ğŸš€ What'sÂ Next?
Add English translation option
Export transcription toÂ .txt orÂ .srt
Add support for other languages
Batch upload

Even if not used for the current project, this app gave me new superpowers. I'm excited to improve and expand it for future research use casesâ€Š-â€Šor even build tools for clinical transcription or education.
GitHub Repo: [your-repo-link-here]
Try the App on Streamlit Cloud: [your-app-link-here]
